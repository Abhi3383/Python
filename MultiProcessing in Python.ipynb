{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Multiprocessing in Python\n",
    "Multiprocessing is a Python module that provides a simple way to run multiple processes in parallel. \n",
    "It allows you to take advantage of multiple cores or processors on your system and can significantly improve the performance of your code.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Importing Multiprocessing\n",
    "We can use multiprocessing by importing the multiprocessing module:\n",
    "import multiprocessing\n",
    "Now, to use multiprocessing we need to create a process object which calls a start() method. \n",
    "The start() method runs the process and then to stop the execution, we use the join() method. \n",
    "Here's how we can create a simple process.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "def my_func():\n",
    "  print(\"Hello from process\", multiprocessing.current_process().name)\n",
    "  process = multiprocessing.Process(target=my_func)\n",
    "  process.start()\n",
    "  process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions\n",
    "The following are some of the most commonly used functions in the multiprocessing module:\n",
    "\n",
    "multiprocessing.Process(target, args): \n",
    "This function creates a new process that runs the target function with the specified arguments.\n",
    "\n",
    "multiprocessing.Pool(processes): \n",
    "This function creates a pool of worker processes that can be used to parallelize the execution of a function across multiple input values.\n",
    "\n",
    "multiprocessing.Queue(): \n",
    "This function creates a queue that can be used to communicate data between processes.\n",
    "\n",
    "multiprocessing.Lock(): \n",
    "This function creates a lock that can be used to synchronize access to shared resources between processes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating a pool of worker processes\n",
    "Creating a pool of worker processes is a common approach to using multiprocessing in Python. \n",
    "The idea is to create a pool of worker processes and then assign tasks to them as needed. \n",
    "This allows you to take advantage of multiple CPU cores and process tasks in parallel.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def process_task(task):\n",
    "    # Do some work here\n",
    "    print(\"Task processed:\", task)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tasks = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    with Pool(processes=4) as pool:\n",
    "        results = pool.map(process_task, tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using a queue to communicate between processes\n",
    "When working with multiple processes, it is often necessary to pass data between them. \n",
    "One way to do this is by using a queue. \n",
    "A queue is a data structure that allows data to be inserted at one end and removed from the other end. \n",
    "In the context of multiprocessing, a queue can be used to pass data between processes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using a lock to synchronize access to shared resources\n",
    "When working with multiprocessing in python, locks can be used to synchronize access to shared resources among multiple processes. \n",
    "A lock is an object that acts as a semaphore, allowing only one process at a time to execute a critical section of code. \n",
    "The lock is released when the process finishes executing the critical section.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def increment(counter, lock):\n",
    "    for i in range(10000):\n",
    "        lock.acquire()\n",
    "        counter.value += 1\n",
    "        lock.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    counter = multiprocessing.Value('i', 0)\n",
    "    lock = multiprocessing.Lock()\n",
    "\n",
    "    p1 = multiprocessing.Process(target=increment, args=(counter, lock))\n",
    "    p2 = multiprocessing.Process(target=increment, args=(counter, lock))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "\n",
    "    print(\"Counter value:\", counter.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import multiprocessing\n",
    "\n",
    "def downloadFile(url, name):\n",
    "  print(f\"Started Downloading {name}\")\n",
    "  response = requests.get(url)\n",
    "  open(f\"files/file{name}.jpg\", \"wb\").write(response.content)\n",
    "  print(f\"Finished Downloading {name}\")\n",
    " \n",
    "url = \"https://picsum.photos/2000/3000\"\n",
    "pros = []\n",
    "for i in range(5):\n",
    "  downloadFile(url, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during execution: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "All downloads finished.\n"
     ]
    }
   ],
   "source": [
    "# Works a .py script\n",
    "\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"files\", exist_ok=True)\n",
    "\n",
    "def downloadFile(url, name):\n",
    "    try:\n",
    "        print(f\"Started Downloading {name}\")\n",
    "        response = requests.get(url, timeout=10)  # Added timeout for network request\n",
    "\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            with open(f\"files/file{name}.jpg\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Finished Downloading {name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {name}, Status Code: {response.status_code}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request error for {name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {name}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://picsum.photos/2000/3000\"\n",
    "    \n",
    "    # Using ProcessPoolExecutor to parallelize downloads\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        l1 = [url for _ in range(5)]  # Same URL for each download\n",
    "        l2 = [i for i in range(5)]  # Unique identifiers for files\n",
    "        \n",
    "        try:\n",
    "            # Map each downloadFile task to a process in the pool\n",
    "            results = executor.map(downloadFile, l1, l2)\n",
    "            \n",
    "            # Results is a generator that yields None, since downloadFile has no return value\n",
    "            for r in results:\n",
    "                pass  # Just iterate through results (not used here)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during execution: {e}\")\n",
    "    \n",
    "    print(\"All downloads finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works a .py script\n",
    "\n",
    "import multiprocessing\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(\"files\", exist_ok=True)\n",
    "\n",
    "def downloadFile(url, name):\n",
    "    try:\n",
    "        print(f\"Started Downloading {name}\")\n",
    "        # Send GET request to URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            with open(f\"files/file{name}.jpg\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Finished Downloading {name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download {name}, Status Code: {response.status_code}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {name}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://picsum.photos/2000/3000\"\n",
    "    pros = []\n",
    "\n",
    "    # Start 5 processes\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=downloadFile, args=(url, i))\n",
    "        p.start()\n",
    "        pros.append(p)\n",
    "\n",
    "    # Wait for all processes to complete\n",
    "    for p in pros:\n",
    "        p.join()\n",
    "\n",
    "    print(\"All downloads finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
